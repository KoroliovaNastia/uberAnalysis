{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZcGWadzEhW9Q"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import operator\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L___pHoJnYYQ"
   },
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kuk0Y_AunptR"
   },
   "source": [
    "For this problem '*Uber Pickups*' dataset was chosen. It represents the data for different New York Uber pickups.\n",
    "Our goal is, by analysing this dataset, to predict the amount of pickups for each line presented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 180
    },
    "colab_type": "code",
    "id": "PhboEoPpjdjn",
    "outputId": "07574509-b85b-4224-edde-b3cba8434b8e"
   },
   "outputs": [],
   "source": [
    "X_data = pd.read_csv('data/trainX.csv')\n",
    "Y_data = pd.read_csv('data/trainY.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "NAVLq5w_kQSM",
    "outputId": "be13d47f-477c-4b6d-cdd2-8913139acf81"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pickup_dt</th>\n",
       "      <th>borough</th>\n",
       "      <th>spd</th>\n",
       "      <th>vsb</th>\n",
       "      <th>temp</th>\n",
       "      <th>dewp</th>\n",
       "      <th>slp</th>\n",
       "      <th>pcp01</th>\n",
       "      <th>pcp06</th>\n",
       "      <th>pcp24</th>\n",
       "      <th>sd</th>\n",
       "      <th>hday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26112</td>\n",
       "      <td>2015-06-12 16:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.1</td>\n",
       "      <td>82.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1014.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26896</td>\n",
       "      <td>2015-06-17 12:00:00</td>\n",
       "      <td>EWR</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1018.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2263</td>\n",
       "      <td>2015-01-15 08:00:00</td>\n",
       "      <td>Queens</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1021.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10453</td>\n",
       "      <td>2015-03-07 15:00:00</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1024.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.551667</td>\n",
       "      <td>18.583333</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19043</td>\n",
       "      <td>2015-04-30 08:00:00</td>\n",
       "      <td>EWR</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1006.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id            pickup_dt   borough  spd   vsb  temp  dewp     slp  pcp01  \\\n",
       "0  26112  2015-06-12 16:00:00       NaN  6.0   9.1  82.0  60.0  1014.2    0.0   \n",
       "1  26896  2015-06-17 12:00:00       EWR  7.0  10.0  72.0  58.0  1018.9    0.0   \n",
       "2   2263  2015-01-15 08:00:00    Queens  3.0  10.0  27.0  17.0  1021.6    0.0   \n",
       "3  10453  2015-03-07 15:00:00  Brooklyn  7.0   9.1  24.0   7.0  1024.3    0.0   \n",
       "4  19043  2015-04-30 08:00:00       EWR  9.0  10.0  49.0  40.0  1006.7    0.0   \n",
       "\n",
       "   pcp06     pcp24         sd hday  \n",
       "0   0.00  0.240000   0.000000    N  \n",
       "1   0.00  0.270000   0.000000    N  \n",
       "2   0.00  0.000000   0.000000    N  \n",
       "3   0.29  0.551667  18.583333    N  \n",
       "4   0.00  0.050000   0.000000    N  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ta4apuXIkUXd"
   },
   "source": [
    "Decision Tree Regressor algorithm will be implemented here to predict the amount of pickups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yFWEgXCxnSgb"
   },
   "source": [
    "# Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_date(dataset):\n",
    "    def str_to_secs(s):\n",
    "        time = datetime.strptime(s,\"%Y-%m-%d %H:%M:%S\").time()\n",
    "        return time.second+time.minute*60+time.hour*3600\n",
    "    def str_to_hour(s):\n",
    "        return datetime.strptime(s,\"%Y-%m-%d %H:%M:%S\").time().hour\n",
    "    data = dataset.copy()\n",
    "    data.pickup_dt = data.pickup_dt.apply(str_to_hour)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_one_hot_encoding(dataset, attr):\n",
    "    # didn't use it\n",
    "    data = pd.DataFrame(dataset, copy=true)\n",
    "    uniques = set(data[attr].values)\n",
    "    uniques.remove('nan')\n",
    "    for value in uniques:\n",
    "        new_value = f'{attr}_{value}'\n",
    "        data[new_value] = (data[attr] == value)\n",
    "    del data[attr]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_data(dataset, column):\n",
    "# data binning for categorizing continous values:\n",
    "\n",
    "    bins_map = {}\n",
    "\n",
    "    idxs, bins = pd.cut(dataset[column], bins=20, labels=False, retbins=True)\n",
    "\n",
    "    for bin_num, border_val in enumerate(bins):\n",
    "        if bin_num == len(bins) - 1:\n",
    "            continue\n",
    "        else:\n",
    "            high = bins[bin_num + 1]\n",
    "        bins_map[bin_num] = {\n",
    "            'low': border_val,\n",
    "            'high': high,\n",
    "            #'amount': amounts[bin_num]\n",
    "        }\n",
    "    return idxs, bins_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(dataset):\n",
    "    dataset_copy = dataset.fillna(value={'borough': 'Unknown'})\n",
    "    dataset_copy = dataset_copy.drop('id', axis='columns')\n",
    "    dataset_copy = transform_date(dataset_copy)\n",
    "    return dataset_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_prepared = prepare_data(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QtapHFCMkig7"
   },
   "outputs": [],
   "source": [
    "merged = pd.merge(X_data, Y_data, on='id')\n",
    "Y = merged['pickups']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RZKjburaky2d"
   },
   "source": [
    "Splitting dataset into 10 equal pieces:\n",
    "\n",
    "(didn't use it - just a small note that can be used for K-fold validation later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XkKpnhUeleWC"
   },
   "outputs": [],
   "source": [
    "X_copy = pd.DataFrame(X_prepared, copy=True)\n",
    "subsets = []\n",
    "amount = int(len(X_copy) / 10)\n",
    "\n",
    "for x in range(0, 10):\n",
    "    subsets.append(X_copy.sample(n=amount))\n",
    "    X_copy.drop(subsets[x].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4eRuFyJ_ylDq"
   },
   "source": [
    "# Implementing Decision Tree Regressor (ID3 type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wxHX6HmoEgvf"
   },
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    \"\"\"class containing methods for tree fitting and prediction making\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._binned_attrs = {}\n",
    "        self.tree_model = None\n",
    "        self.data = None\n",
    "        self.Y = None\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        self.Y = Y\n",
    "        self.data = X.copy()\n",
    "        data = self.data\n",
    "        for attr in self.data:\n",
    "            if len(self.data[attr].unique()) > 30:\n",
    "                self.data[attr], self._binned_attrs[attr] = bin_data(data, attr)\n",
    "        self.tree_model = self._fit_tree(data)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        def find_bins(value, binned_map):\n",
    "            if value < binned_map[0]['high']:\n",
    "                return 0\n",
    "            for bin_num, bin_def in binned_map.items():\n",
    "                low = bin_def['low']\n",
    "                high = bin_def['high']\n",
    "                if low < value <= high:\n",
    "                    return bin_num\n",
    "            return max(binned_map.keys())\n",
    "\n",
    "        data = X.copy()\n",
    "        for attr, bins in self._binned_attrs.items():\n",
    "            data[attr] = data[attr].apply(lambda x: find_bins(x, bins))\n",
    "        \n",
    "        answers = []\n",
    "        for line_idx, line in data.to_dict('index').items():\n",
    "            targets = []\n",
    "            models = [self.tree_model]\n",
    "            while models:\n",
    "                model = models.pop()\n",
    "                if model['type'] == 'leaf':\n",
    "                    targets.extend(model['targets'])\n",
    "                    continue\n",
    "                attr = model['attr_name']\n",
    "                attr_value = line[attr]\n",
    "                if attr_value in model['choices']:\n",
    "                    models.append(model['choices'][attr_value])\n",
    "                else:\n",
    "                    # print(f'Skipping {attr_value} of {attr} for line {line_idx}')\n",
    "                    models.extend(model['choices'].values())\n",
    "            vals = self.Y[targets].values\n",
    "            vals_avg = sum(vals) / len(vals)\n",
    "            vals_stddev = self._standard_deviation(vals)\n",
    "            answers.append(int(vals_avg))\n",
    "        return np.array(answers)\n",
    "    \n",
    "    def _standard_deviation(self, arr):\n",
    "        avg = sum(arr) / len(arr)\n",
    "        stddev = np.sqrt(sum((x - avg)**2 for x in arr) / len(arr))\n",
    "        return stddev\n",
    "\n",
    "    def _variation_coef(self, Y):\n",
    "        stddev = self._standard_deviation(Y)\n",
    "        avg = sum(Y) / len(Y)\n",
    "        return stddev / avg\n",
    "\n",
    "    def _split(self, data, colname, value):\n",
    "    # returns dataframe without given colname which contains only given value of this colname\n",
    "        return data.loc[data[colname] == value, data.columns.drop(colname)]\n",
    "\n",
    "    def _choose(self, data):\n",
    "        def filtered_stddev(attr, value):\n",
    "            col = data[attr]\n",
    "            lines_with_value = data[col == value].index\n",
    "            probability = len(lines_with_value) / len(data)\n",
    "            return probability * self._standard_deviation(self.Y[lines_with_value].values)\n",
    "        def biased_stddev(attr):\n",
    "            return sum(filtered_stddev(attr, value) for value in data[attr].unique())\n",
    "        \n",
    "        best_attr, lowest_biased_stddev = min([(attr, biased_stddev(attr)) for attr in data.columns], key=operator.itemgetter(1))\n",
    "    \n",
    "        return best_attr\n",
    "\n",
    "    def _majority(self, classset):\n",
    "        count = {}\n",
    "        for attr in classset:\n",
    "            if attr not in count.keys():\n",
    "                count[attr] = 0\n",
    "            count[attr] += 1\n",
    "        sorted_class_count = sorted(count.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        return sorted_class_count[0][0]\n",
    "\n",
    "    def _fit_tree(self, data, depth=0):\n",
    "        # if only one entry - return it\n",
    "        # if variation coef is too small - return data\n",
    "        if depth > 30 \\\n",
    "            or data.shape[0] == 1 \\\n",
    "            or abs(self._variation_coef(self.Y[data.index].values) - 0.10) < 1e-10 \\\n",
    "            or data.shape[1] == 0:\n",
    "            return dict(type='leaf', targets=data.index)\n",
    "        # if only one column left - return the majority of it's values (TODO improve function)\n",
    "        if data.columns.size == 1:\n",
    "            best_attr = data.columns[0]\n",
    "        else:\n",
    "            best_attr = self._choose(data)\n",
    "\n",
    "        uniques = data[best_attr].unique()\n",
    "        # else choose best feat, create a node, go recursively\n",
    "        return dict(type='node', attr_name=best_attr, choices={\n",
    "            value: self._fit_tree(self._split(data, best_attr, value), depth + 1) for value in uniques\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/ipykernel_launcher.py:64: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTree()\n",
    "\n",
    "x_small = X_prepared.iloc[:100]\n",
    "y_small = Y[:100]\n",
    "\n",
    "dt.fit(x_small, y_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_final = DecisionTree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/ipykernel_launcher.py:64: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "dt_final.fit(X_prepared, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = pd.read_csv('./data/testX.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prep = prepare_data(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predicted = dt_final.predict(test_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5821"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "dddd = pd.DataFrame([test_X['id'], pd.Series(test_predicted, name='pickups')]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "dddd.to_csv('./data/testY.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Uber_pickups_random_forest_entropy.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
